---
title: "PEC3: Secuencias promotoras en E. Coli"
author: "Demetrio Muñoz Alvarez"
date: '`r Sys.Date()`'
output:
  html_document:
    toc: yes
    toc_depth: 3
  pdf_document:
    keep_tex: no
    number_sections: no
    toc: yes
    toc_depth: 3
params:
  mydata: "promoters.txt"
  seed_pec3: 12345
bibliography: scholar.bib
geometry: margin=2cm
---
```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NULL, cache=TRUE)
options(width=90)
```

```{r working directory, include = FALSE}
# Establecemos el directorio de trabajo.
setwd("C:/Users/Deme/Desktop/Master/Machine Learning/pec3")
```

```{r dinamic_asigns, include = FALSE}
data <- params$mydata
seed <- params$seed_pec3
```

```{r load_libraries, include=FALSE}
library(knitr)
library(kernlab)
library(caret)
library(ggplot2)
```

\newpage

# Algoritmo "Support Vector Machine"

Las máquinas de soporte vectorial (**SVM**) son un tipo de algoritmo de aprendizaje supervisado para tareas de clasificación y regresión. Desarroladas por Vladimir Vapnik y su equipo en la decada de los noventa [@cortes1995support].

El concepto principal de las SVM es separar los datos con el mayor margen posible y de manera homogénea, mediante la identificación del mejor hiperplano. Un **hiperplano** es una superficie de decisión que divide el espacio de características en regiones asociadas con diferentes clases.

Las SVM son capaces de abordar tanto problemas de clasificación lineal como no lineal. En el caso de problemas no lineales, se recurre al uso de funciones kernel. Estas funciones matemáticas transforman el espacio de características original en un espacio de características de mayor dimensión, donde la separación lineal es más fácil de lograr. Algunos ejemplos de funciones kernel comunes incluyen el kernel lineal, el kernel polinómico, el kernel gaussiano, el string kernel, el chi-square kernel, entre otros.

En el ámbito de la bioinformática, las SVM abordan diversas tareas relacionadas con el análisis de datos biológicos, como: 

1.  Clasificación de secuencias genéticas
2.  Análisis de expresión génica
3.  Predicción de estructuras de proteínas
4.  Análisis de imágenes médicas
5.  Análisis de secuencias filogenéticas

Las fortalezas y debilidades que encontramos en las SVM se reflejan en la siguiente tabla [@lantz2019machine]:

```{r table_1, echo = FALSE}
tabla_1 <- data.frame(
  Fortalezas = c("Uso en predicción y clasificación. Uso bastante extendido", "Funciona de forma óptima con ruido", "Facilidad de uso en comparación de las redes neuronales"),
  Debilidades = c("Requiere especificar parámetro C y función de kernel (prueba y error)", "Lento de entrenar, sobre todo a medida que aumenta el número de características", "Al igual que las redes neuronales es difícil de interpretar el funcionamiento interno."))
kable(tabla_1, format = "markdown")
```

# Implementar una función para realizar una transformación one-hot encoding de las secuencias del fichero de datos "promoters.txt".

La función **'onehot_encoding()'** toma las secuencias de ADN de un conjunto de datos y aplica una transformación remplazando cada nucleótido por su vector de 4 componentes. Como resultado crea nuevas columnas para cada nueva componente.

```{r function_onehot}
onehot_encoding <- function(df) {
  # Creamos el diccionario de sustitución para transformar los nucleotidos: 
  nucleotides_dict <- list(
    'a' = c(0, 0, 0, 1),
    'c' = c(0, 1, 0, 0),
    'g' = c(0, 0, 1, 0),
    't' = c(1, 0, 0, 0))
  # Aplicamos la transformación y a la columna sequences de nuestro data frame:
  df$sequences <- lapply(df$sequences, function(sequence) {
    for (nucleotide in names(nucleotides_dict)) {
      sequence <- gsub(nucleotide, paste(nucleotides_dict[[nucleotide]], collapse = ""), sequence)
    }
    return(as.numeric(unlist(strsplit(sequence, ''))))
  })
  # Creamos las columnas para cada componente transformada:
  df[, paste0("V", 1:length(df$sequences[[1]]))] <- do.call(rbind.data.frame, df$sequences)
  # Descartamos la columna original "sequences"
  df$sequences <- NULL
  return(df)
}
```

# Desarrollar un código en R (o en Python) que implemente un clasificador de SVM.

## Leer y codificar los datos con la función one-hot desarrollada.

```{r load_data}
# Cargamos los datos y creamos los nombres de las columnas.
data_pec3 <- read.csv(data, header = FALSE, col.names = c("class", "name", "sequences"))
```

```{r encoding_data}
# Usamos la función para ejecutar la codificación one-hot y transformar nuestras secuencias.
data_onehot <- onehot_encoding(data_pec3)
data_onehot$name <- NULL # Eliminamos la columna "name".
# Transformamos la columna "class" a factor para implementar los algoritmos SVM.
data_onehot$class <- factor(data_onehot$class, levels = c("-", "+")) 
```

## Utilizando la semilla aleatoria 12345, separar los datos en dos partes, una parte para training (67%) y una parte para test (33%).

El conjunto de datos resultante de la implementación de la función **'onehot_encoding()'** se divide en dos partes: un **conjunto de entrenamiento** (67% de las secuencias) y otro **conjunto de prueba** (33% de las secuencias), que se utilizarán para evaluar el algoritmo **SVM** que implementaremos posteriormente. La separación se realiza utilizando una semilla aleatoria para garantizar la reproducibilidad.

```{r data_preaparation_SVM}
set.seed(seed)
# Extraemos los indices para la division de los datos en entrenamiento/prueba.
indices <- sample(1:nrow(data_onehot), size = nrow(data_onehot), replace = FALSE)
# Calculamos el tamaño de los datos de entrenamiento (67%).
train_size <- round(0.67 * nrow(data_onehot))
# Dividimos los datos onehot en entrenamiento/prueba.
train_data <- data_onehot[indices[1:train_size], ]
test_data <- data_onehot[indices[(train_size + 1):nrow(data_onehot)], ] # Conjunto de prueba (33%).
```

## Utilizar el kernel lineal y el kernel RBF para crear sendos modelos SVM basados en el training para predecir las clases en los datos del test.

Para implementar el algoritmo SVM con kernel lineal y RBF usamos la funcion `ksvm` del paquete *'kernlab'* [@kernlab]. Para el kernel lineal usamos la opción **"vanilladot"** y **"rbfdot"** para RBF. Luego mostramos las matrices de confusión de cada modelo con la función `confusionMatrix()`del paquete *'caret'* [@caret].

```{r SVM_models_kernlab}
set.seed(seed)
# Entrenarmos el modelo SVM lineal
svm_linear_model <- kernlab::ksvm(class ~ ., data = train_data, kernel = "vanilladot")
# Predecimos las clases en los datos de prueba para el kernel lineal.
predictions_linear <- predict(svm_linear_model, newdata = test_data)

# Entrenamos el modelo SVM RBF.
svm_rbf_model <- kernlab::ksvm(class ~ ., data = train_data, kernel = "rbfdot")
# Predecimos las clases en los datos de prueba para el kernel RBF.
predictions_rbf <- predict(svm_rbf_model, newdata = test_data)

# Matrices confusión de los modelos lineal y RBF.
linear_model <- caret::confusionMatrix(predictions_linear, test_data$class, positive= "+")
rbf_model <- caret::confusionMatrix(predictions_rbf, test_data$class, positive= "+")
# Mostramos los datos. 
linear_model
rbf_model
```

```{r table_2}
# Mostramos los resultados de los modelo en la siguiente tabla. 
table_2 <- data.frame(
  Modelo = c("SVM Lineal", "SVM RBF"),
  Kappa = round(c(linear_model$overall["Kappa"], rbf_model$overall["Kappa"]),2),
  Accuracy = round(c(linear_model$overall["Accuracy"], rbf_model$overall["Accuracy"]),2),
  Sensitivity = round(c(linear_model$byClass["Sensitivity"], rbf_model$byClass["Sensitivity"]),2),
  Specificity = round(c(linear_model$byClass["Specificity"], rbf_model$byClass["Specificity"]),2))

kable(table_2, caption = "Comparación de Modelos ('kernlab')", format = "markdown")
```
Al comparar los modelos en la tabla anterior  `r if(linear_model$overall["Accuracy"] > rbf_model$overall["Accuracy"]){"observamos que el modelo obtenido con SVM lineal tiene una mayor precisión"}` `r if(linear_model$overall["Accuracy"] < rbf_model$overall["Accuracy"]){"observamos que el modelo obtenido con SVM RBF tiene una mayor precisión"}` `r if(linear_model$overall["Accuracy"] == rbf_model$overall["Accuracy"]){"observamos que ambos modelos tienen la misma precisión"}`. `r if(linear_model$byClass["Sensitivity"] > rbf_model$byClass["Sensitivity"]){"El modelo SVM lineal tiene una mayor sensibilidad"}` `r if(linear_model$byClass["Sensitivity"] < rbf_model$byClass["Sensitivity"]){"El modelo SVM RBF tiene una mayor sensibilidad"}` `r if(linear_model$byClass["Sensitivity"] == rbf_model$byClass["Sensitivity"]){"Ambos modelos tienen la misma sensibilidad"}`. Por último, `r if(linear_model$byClass["Specificity"] > rbf_model$byClass["Specificity"]){"el modelo SVM lineal tiene una mayor especificidad"}` `r if(linear_model$byClass["Specificity"] < rbf_model$byClass["Specificity"]){"el modelo SVM RBF tiene una mayor especificidad"}` `r if(linear_model$byClass["Specificity"] == rbf_model$byClass["Specificity"]){"ambos modelos tienen la misma especificidad"}`.

En conclusión, si ambos modelo son muy similares selecionariamos el modelo más sencillo.

## Usar el paquete caret con el modelo svmLinear para implementar un SVM con kernel lineal y 3-fold crossvalidation. Comentar los resultados.

En este apartado vamos a repetir el modelo SVM lineal usando el paquete *'caret'* con la función `train()`y el metodo 'svmLinear'. Usamos una validacion cruzada de 3-fold. Además, utilizamos los mismos conjutnos de entrenamiento y prueba de los modelos anteriores.

```{r SVM_models_linear_caret}
set.seed(seed)

# Entrenamos el modelo SVM con kernel lineal y la funcion 'train()'del paquete "caret".
svm_linear_caret_model <- caret::train(class ~ ., data = train_data, method = "svmLinear", trControl = trainControl(method = "cv", number = 3))

# Predicciones del modelo.
prediction_linear_caret <- predict(svm_linear_caret_model, test_data)

# Matriz de confusión.
linear_caret_model <- confusionMatrix(prediction_linear_caret, test_data$class, positive="+")
linear_caret_model
```

Si lo comparamos con el modelo lineal realizado con el paquete 'kernlab' anterior `r if (all.equal(linear_model$overall, linear_caret_model$overall)) {"observamos que ambos modelos tienen las mismas métricas"} else {"Observamos que el modelo obtenido con SVM lineal del paquete 'caret'y el paquete 'kernlab' tiene resultados diferentes"}`

En resumen, el modelo generado con el paquete 'caret', muestra un **precisión** del `r round(linear_caret_model$overall["Accuracy"]*100,2)`% e indica el porcentaje de predicciones correctas. Los valores de **sensibilidad y especificidad**, `r round(linear_caret_model$byClass["Sensitivity"]*100,2)`% y `r round(linear_caret_model$byClass["Specificity"]*100,2)`%, muestran la tasa de verdaderos positivos y tasa de verdaderos negativos respectivamente. Como última metrica, el valor **Kappa** del modelo, con un valor `r round(linear_caret_model$overall["Kappa"]*100,2)`%, mide la concordancia entre observaciones más allá de lo esperado por azar, un valor mayor que 0 indica que el modelo las predicciones del modelo son mejores de las esperadas aleatoriamente.


## Evaluar el rendimiento del algoritmo SVM con kernel RBF para diferentes valores de los hiperparámetros C y sigma. Orientativamente, se propone explorar valores de sigma en el intervalo (0.005,0.5) y valores de C en el intervalo (0.1, 2). Mostrar un gráfico del rendimiento según los valores de los hiperparámetros explorados.

Para el último modelo, implementamos un algoritmo de clasificación SVM con el kernel 'RBF'. Utilizamos la función *'train()'* del paquete *'caret'* con el método *'svmRadial'*. Además, en este caso, llevamos a cabo una exploración de varios valores para los hiperparámetros C y sigma, los cuales visualizaremos en un gráfico.

```{r SVM_models_RBF_caret}
set.seed(seed)

# Entrenamos el modelo RBF y establecemos los intervalos de sigma y C. 
svm_rbf_caret_model <- train(class ~ ., data = train_data, method = "svmRadial",
                             trControl = trainControl(method = "cv", number = 5),
                             tuneGrid = expand.grid(C = seq(0.1, 2, by = 0.1),
                                                    sigma = seq(0.005, 0.5, by = 0.05)))

# Mostramos los hiperparametros mas optimos selecionados. 
svm_rbf_caret_model$finalModel

# Creamos y mostramos el grafico de rendimiento para los distintos valores de sigma y C.
ggplot(svm_rbf_caret_model$results, aes(x = C, y = Accuracy, color = as.factor(sigma))) +
  geom_line() +
  labs(title = "Rendimiento del modelo SVM ('caret') con kernel RBF",
       x = "Valor de C",
       y = "Accuracy",
       color = "Valor de sigma") +
  scale_color_discrete(name = "Valor de sigma")

# Predicciones del modelo.
prediction_rbf_caret <- predict(svm_rbf_caret_model, test_data)
# Calclulamos y mostramos la matrix de confusión.
rbf_caret_model <- confusionMatrix(prediction_rbf_caret, test_data$class, positive= "+")
rbf_caret_model

```
El modelo **'svm_rbf_caret_model'** ha selecionado el valor **`r svm_rbf_caret_model$results[which.max(svm_rbf_caret_model$results$Accuracy),2]`** para el hiperpárametro  sigma y **`r svm_rbf_caret_model$results[which.max(svm_rbf_caret_model$results$Accuracy),1]`** para el parámetro C, la precisión que se consigue con estos parametros es del **`r round(svm_rbf_caret_model$results[which.max(svm_rbf_caret_model$results$Accuracy),3],2)*100`**%. En el gráfico podemos analizar como varía la precisíon del modelo dependiendo de los diferentes valores de sigma y C y observar que combinación de valores da la mejor precisión.

Con los valores optimos selecionados y las predicciones realizadas con el conjunto de pruebas el modelo muestra las siguientes métricas: precisión del `r round(rbf_caret_model$overall["Accuracy"]*100,2)`%, sensibilidad del `r round(rbf_caret_model$byClass["Sensitivity"]*100,2)`%, especificidad del `r round(rbf_caret_model$byClass["Specificity"]*100,2)`% y un valor kappa de `r round(rbf_caret_model$overall["Kappa"]*100,2)`%.


## Crear una tabla resumen de los diferentes modelos y sus rendimientos. Comentar y comparar los resultados de la clasificación en función de los valores generales de la clasificación como accuracy y otros para los diferentes clasificadores obtenidos. ¿Qué modelo resulta ser el mejor?

```{r model_camparation}
# Mostramos los resultados de todos los modelos. 
table_3 <- data.frame(
  Modelo = c("Kernlab SVM Lineal", "Kernlab SVM RBF", "Caret SVM Lineal", "Caret SVM RBF"),
  Kappa = round(c(linear_model$overall["Kappa"], rbf_model$overall["Kappa"], linear_caret_model$overall["Kappa"], rbf_caret_model$overall["Kappa"]), 2),
  Accuracy = round(c(linear_model$overall["Accuracy"], rbf_model$overall["Accuracy"], linear_caret_model$overall["Accuracy"], rbf_caret_model$overall["Accuracy"]),2),
  Sensitivity = round(c(linear_model$byClass["Sensitivity"], rbf_model$byClass["Sensitivity"], linear_caret_model$byClass["Sensitivity"], rbf_caret_model$byClass["Sensitivity"]),2),
  Specificity = round(c(linear_model$byClass["Specificity"], rbf_model$byClass["Specificity"],linear_caret_model$byClass["Specificity"], rbf_caret_model$byClass["Specificity"]),2))

kable(table_3, caption = "Comparación de Modelos ('kernlab vs Caret')", format = "markdown")
```

En general, los cuatro modelos son muy similares y no se observan diferencias al implementar los modelos con un paquete específico. Los modelos lineal y RBF son idénticos, ya sea que utilicemos el paquete *caret* o *kernlab*.

En conclusión, dado que los modelos presentan métricas identicas, se podría considerar que el modelo lineal es la mejor opción. Además, al ser modelos idénticos, no hay distinción significativa entre elegir el modelo lineal realizado con el paquete *kernlab* o *caret*.

\newpage

# Referencias

